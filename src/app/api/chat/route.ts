"use server";

import { pinecone, PINECONE_INDEX } from "@/lib/pinecone";
import { openai } from "@ai-sdk/openai";
import { OpenAIEmbeddings } from "@langchain/openai";
import { streamText } from "ai";
import { PineconeStore } from "@langchain/pinecone";
import { addMessage, getMessage } from "@/drizzle/action";

export async function POST(req: Request) {
  const { messages, url, chatId } = await req.json();

  await addMessage({
    chatId,
    body: messages[messages.length - 1].content,
    role: "user",
  });

  const embeddings = new OpenAIEmbeddings({
    model: "text-embedding-3-small",
  });

  const pineconeIndex = pinecone.Index(PINECONE_INDEX);

  const vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
    pineconeIndex,
    namespace: url,
  });

  const query = messages[messages.length - 1].content;
  const results = await vectorStore.similaritySearch(query);

  const prevMessages = await getMessage({ chatId });

  const result = await streamText({
    model: openai("gpt-3.5-turbo-0125"),
    temperature: 0,
    prompt: `You are a friendly AI assistant augmented with an Pinecone Vector Store.
      To help you answer the questions, a context will be provided and you can also use ${url}. This context is generated by querying the vector store with the user question.
      Answer the question at the end using only the information available in the context (or previous conversaton if needed) in markdown format.
      If the answer is not available in the chat history or context, do not answer the question and politely let the user know that you can only answer if the answer is available in context or the chat history.
      WORD COUNT:50 words(minimum)

      \n----------------\n

      PREVIOUS CONVERSATION:
      ${prevMessages.map((message) => {
        if (message.role === "user") return `User: ${message.body}\n`;
        return `Assistant: ${message.body}\n`;
      })}

      \n----------------\n

      CONTEXT:
      ${results.map((r) => r.pageContent).join("\n\n")}
      
      -------------

      Question: ${query}
      Helpful answer:`,
    async onFinish(data) {
      console.log(chatId, data.text);
      await addMessage({
        chatId: chatId,
        body: data.text,
        role: "assistant",
      });
    },
  });

  return result.toDataStreamResponse();
}
