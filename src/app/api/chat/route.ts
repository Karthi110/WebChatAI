import { pinecone } from "@/lib/pinecone";
import { openai } from "@ai-sdk/openai";
import { OpenAIEmbeddings } from "@langchain/openai";
import { streamText } from "ai";
import { PineconeStore } from "@langchain/pinecone";

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  const { messages } = await req.json();
  // await vectorizeData("https://ui.shadcn.com/docs");
  const embeddings = new OpenAIEmbeddings({
    model: "text-embedding-3-small",
  });

  const pineconeIndex = pinecone.Index("indexedurls");

  const vectorStore = await PineconeStore.fromExistingIndex(embeddings, {
    pineconeIndex,
    namespace: "https:/ui.shadcn.com/docs/components/button",
  });

  const query = messages[messages.length - 1].content;
  const results = await vectorStore.similaritySearch(query);
  console.log(query);

  const result = await streamText({
    model: openai("gpt-3.5-turbo-0125"),
    temperature: 0,
    messages: [
      {
        role: "system",
        content: `
            You are a friendly AI assistant augmented with a Pinecone Vector Store.
            To help you answer questions, a context will be provided. This context is generated by querying the vector store with the user question.
            You must answer the question using **only the information available** in the context and chat history. If the information is unavailable, do not answer the question, and politely let the user know that you can only answer if the answer is present in the provided context or chat history.
      
            Format your response in **markdown**:
            1. Provide **bold clickable links** for titles.
            2. Include **code snippets** where relevant.
            3. Use references/links with **superscripts** for citations like in research papers (e.g., "useful context¹ additional context²").
      
            If the answer is not available:
            - Respond with: "I'm sorry, I can only provide answers based on the information available in the context or chat history."
      
            Example format:
            **[Title or link]**
            Description of the response.
      
            \`\`\`ts
            // Example code snippet here
            \`\`\`
      
            Reference¹, Reference²
          `,
      },
      {
        role: "user",
        content: `
      Use the following pieces of context (or previous conversation if needed) to answer the user's question in markdown format. 
      
      If you don't know the answer, just say that you don't know, don't try to make up an answer.
              
      \n----------------\n
      
      PREVIOUS CONVERSATION:

      
      \n----------------\n
      
      CONTEXT:
      ${results.map((r) => r.pageContent).join("\n\n")}
      
      USER INPUT: ${query}
          `,
      },
    ],
  });

  return result.toDataStreamResponse();
}
